\section{Prototipa realizācija}
Lai ilustrētu šādas transformāciju sistēmas izstrādes iespējamību, tika izstrādāts sakrišanu meklēšanas mehānisma prototips. Šī nodaļa apraksta prototipa vispārīgās īpašības un pieejas, kas tika lietotas tā realizācijā. Prototips vienkāršības un izstrādes ātruma dēļ tika rakstīts Python valodā, kas ir skriptu valoda, un tāpēc prototips ir viegli palaižams un atkļūdojams uz jebkuras mašīnas ar uzstādītu 2.7.0 Python versiju.

Šīs nodaļas apakšnodaļa~\ref{subsec:solution_problems} savukārt apraksta problēmas ar kurām saskārās darba autors un izņēmumus, kas pagaidām netiek implementēti prototipā.

\fixme{Pārrakstīt atkarībā no satura}

\subsection{\label{subsec:solution_approach}Vispārīgā pieeja}
Šī apakšnodaļa apraksta sistēmas prototipa darbību virkni un prototipa iespējas uz doto brīdi. Šeit ir tikai vispārīgi aprakstīta darba gaita, bez pamatojumiem, kāpēc šāda rīcība ir izvēlēta, bet apakšnodaļā~\ref{subsec:solution_motivation} tiks sīkāk aprakstīts, kāpēc tas tika izveidots tieši šādi.

Prototips imitē darbu reālajā vidē, saņemot pa vienam tokenus no ieejas plūsmas no klases, kas imitē leksera darbu. Tā kā šī sistēma nav parsētājs, tā neapstrādā tokenus, kas neattiecās uz sistēmas darbu. Tas nozīmē, ka kamēr sistēmā neeksistē neviena regulārā izteiksme, tā palaiž garām tokenus un neapstrādā tos. Tiklīdz tiek sastapts makro sākuma tokens, prototips uzsāk regulārās izteiksmes parsēšanu. Parsēšanas procesā tiek izveidots nedeterminēts galīgs automāts. Tālāk šīs automāts tiek determinēts un minimizēts, tātad katra regulāra izteiksme tiek pārveidota minimālajā determinētā automātā, tātad ir optimizēta pēc izpildes laika.

Tikko parādās vismaz divas regulārās izteiksmes, sistēma sapludina kopā to determinētos automātus, kas tiek darīts lai samazinātu tokenu virknes sakrišanas atrašanas laiku. Tā izteiksme, kas tika ielasīta agrāk būs ar lielāku prioritāti nekā tā, kas ir ielasīta vēlāk. Tātad ja secīgi tiks ielasītas divas izteiksmes \verb|{id} '(' ')'| un \verb|{id} '(' ({real}*) ')'|, tad ielasot virkni \verb|{id:foo} '(' ')'| tiks akceptēta pirmā izteiksme. Gadījumā, ja izteiksmes tiks ielasītas pretējā secībā, pirmā izteiksme nekad netiks atpazīta, jo otrā izteiksme pārklāj visas pirmās izteiksmes korektās ieejas.

Sistēma arī ļauj veidot regulārās izteiksmes ar specifiskām tokenu vērtībām. Piemēram, regulārā izteiksme \verb|{id:foo}| sagaidīs tieši identifikatoru \verb|foo|, bet izteksme \verb|{id}| sagaidīs jebkuru identifikatoru.

Prototips strādā pēc $greedy$ principa - tas akceptē visgarāko iespējamo šablona sakritību. Ja eksistē divi šabloni, kas dod sakritību ar vienādu garumu, tad tiek ņemtas vērā prioritātes. Tas var notikt, ja eksistē divi šabloni, viens no kuriem satur vērtības prasību tokenam, bet otrs - nesatur. Ja tiek ielasītas divas izteiksmes  \verb|{id:foo} '(' {real}* ')'| un \verb|{id} '(' {real}* ')'|, tad virkne \verb|{id:foo} '(' {real:4.5} ')'| derēs abiem šabloniem. Bet tā kā šablons \\ \verb|{id:foo} '(' {real}* ')'| tika ielasīts pirmais, tieši tas arī būs akceptēts.

Viena no galvenām šīs sistēmas īpašībām ir iespēja atšķirt programmatūras tvērumus. Ja sistēma darba gaitā sastapās ar konteksta sākuma simbolu, tā izveido eksistējošā automāta kopiju un tālāk tvēruma makro pievieno šai kopijai. Tvēruma iekšienē strādā tādi paši likumi par izteiksmju prioritātēm - izteiksme, kas bija agrāk ir ar lielāku prioritāti. Bet makro, kas ir specifiski tvērumam ir ar lielāku prioritāti nekā vispārīgāki makro. Tātad jā pēc kārtas atnāks \verb|{id} '(' ')'|, tvēruma sākuma tokens un \verb|{id} '(' {real}* ')' |, tad otrā tvēruma ietvaros virkne \verb|{id:foo} '(' ')'| tiks akceptēta ar otro regulāro izteiksmi. Pēc izejas no tvēruma tā specifiskais automāts tiek izmests ārā un darbs tiek turpināts ar automātu no iepriekšējā tvēruma līmeņa.

Tvērumu pārvalde ir implementēta šādā veidā, jo sapludinātā automāta atbrīvošana no vairs nevajadzīgiem pamestā tvēruma stāvokļiem ir diezgan darbietilpīgs uzdevums. Ja $n$ ir tvēruma regulāro izteiksmju daudzums un $m$ - maksimālais nesapludinātā automāta garums, tad dzēšanai būs vajadzīgs vismaz $O(n*m)$ laiks. 

Tad, kad atnāk kaut kādi tokeni, kas neatzīmē makro sākšanās, sistēma izpilda pārejas starp sapludinātā automāta stāvokļiem un atceras tokenus, kurus jau ir nolasījusi. Sistēma atrod garāko virkni, kas atbilst kādam no šabloniem un tad atgriež tās identifikatoru un nolasīto tokenu virkni, lai turpmāk transformēšanas mehānisms varētu pārstrādāt to jaunajā virknē.

Pieņemot, ka transformēšanas sistēma ir izstrādāta, tālākā darba gaita būs sekojoša. Transformēšanas sistēma aizstāv ielasīto virkni ar citu, kas ir konstruēta pēc akceptētās regulārās izteiksmes noteikumiem. Tad sakrišanas meklēšanas sistēmas darbs tiek uzsākts no aizvietotās virknes sākuma.

Sistēma turpina darbu aprakstītā gaitā līdz ko neviens no šabloniem vairs netiek akceptēts. Pēc sistēmas apstāšanās tiek iegūta jauna tokenu virkne, kas tika apstrādāta attiecīgi kodā ierakstītiem makro. Kad sistēma tiks integrēta ar reālu kompilatoru, tā strādās paralēli ar parsētāju un sistēmas izejas tokenu virkne tiks apstrādāta ar standartiem valodas likumiem.

\subsection{Lietotie algoritmi}
\label{subsec:solution_algorithms}

\subsubsection{Determinizācija}
\fixme{Uzrakstīt!}

\subsubsection{Minimizācija}
\fixme{Uzrakstīt!}

\subsubsection{Apvienošana}
\fixme{Uzrakstīt!}

\subsection{\label{subsec:solution_motivation}Realizācijas pamatojums}
\fixme{Uzrakstīt!}

Kāpēc sapludina visu kopā, kāpēc minimizē?

Kāpēc šīm uzdevumam neder jau eksistējošas regulāro izteiksmju bibliotēkas. Kāpēc  neder vispārpieņemtie automātu apvienošanas algoritmi.
Regulāro izteiksmju dzinēji strādā ar tekstu, nevis ar tokeniem, nav vērts mēģināt pielāgot. Automātu apvienošana - visur aprakstītās pieejas nesaglabā, pie kāda no automātiem pieder katrs stāvoklis, it īpaši akceptējošie stāvokļi. Mums ir svarīgi zināt, kāds no automātiem ir akceptēts, jo no tā ir atkarīgs, kura no produkcijām tiks lietota. 

\subsection{\label{subsec:solution_problems}Izņēmumi}

\fixme{Papildināt}

\subsubsection{Transformācijas}
Šīs prototips nenodarbojas ar tokenu virkņu transformācijām, jo tā nav sakrišanu meklēšanas mehānisma 

\subsubsection{Produkcijas}
Prototipā pagaidām nav implementēta apstrādes dalīšana pa gramatikas produkcijām, visas regulārās izteiksmes ir sapludinātas vienā automāta. Regulāro izteiksmju dalīšana pa tipiem tiks izstrādāta vēlāk, kad tiks uzsākta integrācija un sadarbība ar reālu kompilatoru. Tā varētu tikt implementēta līdzīgi tam, kā tiek realizēti konteksti - pa vienam sapludinātam automātam priekš katra produkcijas tipa.

\subsubsection{Tokenu mantošana}
Sistēma nezin neko par valodas gramatiku. Tieši tāpēc tokens \verb|{real}| netiks uztverts ka \verb|{expr}|, kaut arī racionāls skaitlis ir izteiksme. Tā kā sistēmai jābūt neatkarīgai no valodas gramatikas, šī hierarhija nav iekodējama transformāciju sistēmā. To ir jānodrošina parsētājam, attiecīgi apstrādājot tokenus un apkopojot to nozīmi. Par to arī būs jārūpējas programmētājam rakstot savas makro izteiksmes.

\subsubsection{Tokenu vērtības}
 Vienlaikus \verb|{id:f}| un \verb|{id}| ievieš nedeterminētību, kaut arī visi automāti sistēmā ir determinizēti.
