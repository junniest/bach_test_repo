\section{\label{sec:extendedbullshit}Uzdevuma pamatojums}

\subsection{Par programmēšanas valodu reprezentāciju}

Programmēšanas valodas ir jēdzienu sistēma, kas ļauj aprakstīt algoritmus. Šai sistēmai jābūt saprotamai programmētājam, tāpēc tiek meklēti veidi, kā tās sintaksi var nodefinēt formāli. Vienkāršs un intuitīvi saprotams rīks, kas der šīm uzdevumam, ir kontekstneatkarīgas gramatikas.

Kontekstneatkarīgas gramatikas piedāvāja N. Homskis, kas plānoja lietot tos lai ieveidotu reālo cilvēku valodu modeļus. Šinī jomā tās gandrīz netiek lietotas, jo dabiskās valodas ir pārāk sarežģītas un ar daudziem izņēmumiem no gramatikas likumiem. Tomēr šīs gramatikas tiek lietotas lai vispārināti aprakstītu programmēšanas valodu sintaksi. Programmēšanas valodas globālā līmenī nav kontekst-neatkarīgas, bet tomēr tās ir neatkarīgas lokāli. Kaut arī ne visas programmēšanas valodu īpašības var aprakstīt ar kontekstneatkarīgām gramatikām, tās ir ērti lietot lai parādīt valodas konstrukciju struktūru.

Kontekstneatkarīgas gramatikas sastāv no četrām daļām. Pirmā ir simbolu kopa, kas tiek saukta par termināliem simboliem. Otrā ir simbolu kopa, kas tiek saukta par netermināliem simboliem. Trešā ir gramatikas sākuma simbols, kas ir viens no neterminālu simbolu kopas. Un, beidzot, ceturtā gramatikas daļa ir pārrakstīšanas likumu kopa. Terminālie simboli ir gramatikas definētās valodas vārdnīca. No tiem tiks sastādīta valoda, kuru definē dotā gramatika. Neterminālie simboli, savukārt, var tikt apskatīti ka termināļu un termināļu virkņu klases.

Pārrakstīšanas likumi tiek pierakstīti izskatā \verb|A| $\rightarrow$ \verb|b|, kur \verb|A| ir viens no netermināliem simboliem, bet b ir neterminālu un terminālu simbolu virkne. Kad kāda likuma kreisē puse parādās apstādāmo simbolu rindā, rinda var tikt pārrakstīta aizvietojot kreisēs puses netermināli ar labo likuma daļu. \verb|A| $\xRightarrow[G]{*}$ \verb|b| parāda, ka \verb|A| var tikt pārveidots virknē \verb|b| lietojot gramatikas $G$ pārrakstīšanas likumus. Šādas secīgu pārveidojumu rinda tiek saukta par atvasinājumu. \cite{Shutt:AdaptiveGrammars}

Pārveidojumu rindas var tikt attēlotas koku veidā. Šīs koks skaidri parāda kā simboli no termināļu virknes tiek grupēti apakšvirknēs, katra no kurām pieder kādam no netermināliem simboliem. Bet vēl svarīgāk, šīs koks, ko sauc par parsēšanas koku, ir struktūra, kas reprezentē apstrādājamo programmu. Kompilatorā šāda struktūra veicina programmas izejas teksta translāciju uz izpildāmu kodu. Gadījumā, ja gramatikā eksistē divi parsēšanas koki vienam un tam pašam atvasinājumam, gramatika ir neviennozīmīga. Neviennozīmības padara gramatikas nelietojamas programmēšanas valodu aprakstam, jo šadā gadījumā kompilators nevarēs izsekot pareizu programmas struktūru. \cite{Hopcroft:IntroAutomataTheory}

Parsētāji ir programmas, kas izpilda programmas teksta pārstrādi parsēšanas kokā. 

Vairākums parsētāju mūsdienās aktuālākam valodām (piemēram C/C++) ir rakstīti manuāli. 
Parsētāju tipi - LR, LL, to trūkumi

\fixme{paskaidrot, no nozīmē reducēt gramatikas likumus}

Bet parsētāji strādā ar tokeniem, nevis ar leksēmām. 

Pirmā programmas kompilēšanas fāze ir leksiskā analīze jeb skanēšana. Tās laikā leksiskais analizators lasa ieejas simbolu virkni (programmas izejas tekstu) un veido jēdzīgas simbolu grupas, kas ir sauktas par leksēmām. Katrai leksēmai leksiskais analizators izveido speciālu objektu, kas tiek saukts par tokenu. Katram tokenam ir glabāts tokena tips, ko lieto parsētājs lai izveidotu programmas struktūru. Ja ir nepieciešams, tiek glabāta arī tokena vērtība, parasti tā ir norāde uz elementu simbolu tabulā, kurā glabājas informācija par tokenu - tips, nosaukums. Simbolu tabula ir nepieciešama tālākā kompilatora darbā lai paveiktu semantisko analīzi un koda ģenerāciju. Šajā darbā vienkāršības dēļ tiks uzskatīts, ka tokena vērtības ailītē glabāsies   leksēma, ko nolasīja analizators. Tālāk tokeni tiks apzimēti šādā veidā:

\begin{verbatim}
{token-type : token-value}
\end{verbatim}

Nolasīto tokenu virkne tiek padota parsētājam tālākai apstrādei.

Piemēram apskatīsim nelielu programmas izejas koda gabalu - \verb|sum = item + 5|. Šīs izejas kods var tikt sadalīts sekojošos tokenos:
\begin{enumerate}
\item \verb|sum| ir leksēma, kas tiks pārtulkota tokenā \verb|{id:sum}|. \verb|id| ir tokena klase, kas parāda, ka nolasītais tokens ir kaut kāds identifikātors. Tokena vērtībā nonāk identifikatora nosaukums \verb|sum|.
\item Piešķiršanas operators \verb|=| tiks pārveidots tokenā \verb|{=}| Šīm tokenam nav nepieciešams glabāt vērtību, tāpēc otrā tokena apraksta komponente ir izlaista. Lai atvieglotu tokenu virkņu uztveri šī darba ietvaros operatoru tokenu tipi tiks apzīmēti ar operatoru simboliem, kaut arī pareizāk būtu izveidot korektus tokena tipu nosaukumus, piemēram \verb|{assign}|.
\item Leksēma \verb|item| analoģiki \verb|sum| tiks pārtulkota tokenā \verb|{id:item}|.
\item Summas operators \verb|+| tiks pārtulkots tokenā \verb|{+}|.
\item Leksēma 5 tiks pārtulkota tokenā \verb|{int:5}|.
\end{enumerate}

Tātad izejas kods \verb|sum = item1 + 5| pēc leksiskās analīzes tiks pārveidots tokenu plūsmā \verb|{id:sum}, {=}, {id:item1}, {+}, {int:5}|. \cite{DragonBook}

Šī darbā arī tiek lietots jēdziens pseido-tokens. Pseido-tokens ir citu tokenu grupa, kas tiek aizvietota ar vienu objektu. Tas var tikt darīts, lai vienreiz noparsētu izteiksmi nevajadzētu apstrādāt vēlreiz. Tokenu aizvietošana ar pseido-tokeniem notiek gramatikas likumu reducēšanas brīdī. Kad, piemēram, tokenu virkne \verb|{id:a} '+' {id:b}| tiek atpazīta ka derīga izteiksme gramatikas ietvaros, tā var tikt aizvietota ar pseido-tokenu \verb|{expr:a + b}|.

\subsection{\label{subsec:dynamicgrammars}Par dinamiskām gramatikām}

Starp īpašībām, kuras nevar aprakstīt ar bezkonteksta gramatikām ir leksiskais tvērums (lexical scope) un statiskā tipizācija (static typing).

\fixme{Uzrakstīt!}
Dinamiskas vai adaptīvās gramatikas ir gramatiskais formālisms, kas ļauj modificēt gramatikas likumu kopu ar gramatikas rīkiem. \cite{Shutt:AdaptiveGrammars}

Dinamiskas gramatikas, kas tās ir. Fakti par to, ka tās jau ir pētītas un reāli implementējamas un lietojamas. Reālais labums no tām.
\fixme{No otras puses kāpēc tās daudz nepētīja un daudz reāli nelieto.} Tās vispārīgā gadījumā ir nekontrolējamas.

\subsubsection{Kā tos parasti vēlās lietot}
adding grammar rules when adding a variable - makes static semantics easier to control.

BUT: problems with scope, recursion and other stuff \cite{Christiansen:SurveyAdaptableGrammars}