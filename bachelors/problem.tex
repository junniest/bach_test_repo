\section{\label{s:motivation}Darba pamatojums}

Uz doto brīdi vairākumam mūsdienīgo programmēšanas valodu eksistē standarti. Pateicoties šim faktam, ir iespējams izstrādāt dažādus kompilatorus vienai un tai pašai valodai. Bet šiem standartiem ir jāmainās, lai valodas varētu attīstīties un paplašināt savas iespējas un lietojamību. Dažreiz šīs izmaiņas ir tik nopietnas, ka prasa ievērojamas parsētāja modifikācijas, lai tiktu atbalstītas, bet dažreiz tās ir tikai sintaktiskas, piem. sintaktiskā cukura\footnote{Sintaktiskais cukurs (\emph{syntactic sugar}) ir speciālas konstrukcijas, kas tiek pievienotas lai to padarītu saprotamāku un lasāmāku cilvēkam. Šīs konstrukcijas nemaina valodas funkcionalitāti, bet gan atvieglo tās lietošanu. Izplatīts sintaktiskā cukura piemērs ir C valodas konstrukcija \texttt{a[i]}, kas patiesībā ir \texttt{*(a + i)}.} ieviešana.

Bieži izmaiņas ir valodas lietotāju iniciētas, jo tikai aktīvi lietojot valodu var izprast, kā tai trūkst, lai tā tiešām kļūtu par ērtu un populāru izstrādes rīku. Piedāvāt savas izmaiņas var dažādos veidos - informējot valodas izstrādātāju par kādas iespējas trūkumu, piedāvājot ielāpus kompilatoram, u.t.t.. Bet jebkādai izmaiņai ir nepieciešams atbalsts un lietotāju kvorums, kas vēlās šo izmaiņu lietot. To ir diezgan grūti dabūt ar šādiem izmaiņu pieprasījumiem.

Tomēr jebkādas, pat nebūtiskas, valodas sintakses izmaiņas parasti prasa kompilatora vai vairāku kompilatoru pārstrādi. Tas notiek tādēļ, ka programmēšanas valodas bieži iekļauj ļoti ierobežotas sintakses mainīšanas iespējas, vai arī neiekļauj šādu iespēju vispār. 

Šīs darbs apskata iespēju lietot adaptīvo gramatiku principu, lai izvairīties no kompilatora pārstrādes nebūtisku sintakses izmaiņu gadījumā. Tas nozīmē, ka valodai jāsatur konstrukcijas, kas parsēšanas laikā var modificēt un paplašināt pašas valodas sintaksi.

Viens no metodēm, kā varētu izpildīt pašmodificēšanas uzdevumu ir izveidot kross\--kom\-pi\-la\-to\-ru, kas transformētu jauno sintaksi tā, lai standarta kompilators to varētu atpazīt. Bet šīs metodes problēma ir tas, ka lielākas daļas moderno valodu sintaksi ir neiespējams noparsēt lietojot automātiskos rīkus. Zemāk ir piedāvāti daži piemēri gadījumiem no populāras valodas C, kad automātiskā parsēšana ir neiespējama.

\begin{enumerate}
\item
Valodā C lietotājs var nodefinēt patvaļīgu tipu lietojot konstrukciju \verb|typedef|. Šāda veida iespēja padara neiespējamu šādas izteiksmes apstrādi \verb|(x) + 5|, ja vien mēs neesam pārliecināti, kas ir \verb|x| - tips vai mainīgais. Ja \verb|x| ir tips, tad šī izteiksme pārveido izteiksmes \verb|+ 5| vērtību uz tipu \verb|x|. Ja \verb|x| ir mainīgais, tad šī izteiksme nozīmē vienkāršu mainīgā \verb|x| un vērtības \verb|5| saskaitīšanu. 
\item
Pieņemsim, ka ir iespēja paplašināt C valodas sintaksi ar infiksu operatoru \verb|++| un pierakstīt konstanšu masīvus \verb|[1, 2, 3]| veidā. Tad izteiksme \verb|a ++ [1]| būtu nepārsējama, jo eksistē vismaz divi to interpretācijas veidi. Tas varētu tikt saprasts ka postfiksā operatora \verb|++| pielietošana mainīgam \verb|a| un tad \verb|a| indeksēšana ar \verb|[1]|. Vai arī tas varētu būt divu masīvu \verb|a| un \verb|[1]| konkatenācija.
\end{enumerate}

Dažreiz arī programmatūras koda dalīšana pa tokeniem ir atkarīga no šī koda konteksta, kas padara ne tikai parsēšanas procesu, bet arī leksēšanas procesu neautomatizējamu.

\begin{enumerate}
\item
Valoda C++ ļauj lietotājam izveidot ligzdveida veidnes, piemēram, šādas \\ \verb|template <typename foo, list <int>>|. Šajā gadījumā simboli \verb|>>| aizver divas atvērtās grupas pēc kārtas. Lai tas tiešām būtu atpazīts, ka grupu aizvēršana, lekserim jāzin simbolu konteksts, jo parasti simbolu kombinācija \verb|>>| nozīmē operāciju pārbīdei pa labi.
\item
Gadījumā, ja lietotājam ir dota iespēja definēt savus operatorus, ieviešot operatoru, kas pārklāj eksistējošos, ir jāmaina leksēšanas likumus. Piemēram, ja lietotājs definē unāru operatoru \verb|+-|, tad izteiksmei \verb|+-5| ir jābūt saprastai ka \verb|(+-, 5)|, nevis ka \verb|(+, -, 5)|.
\end{enumerate}

Apskatītie piemēri dod iespēju secināt, ka automātisku parsētāju ģeneratoru lietošana var būt tik pat sarežģīta, ka parsētāja rakstīšana ar rokām. Izrādās, ka daudzām eksistējošām valodām parsētāji arī tiek rakstīti manuāli (piemēram C/C++/ObjectiveC kompilators GNU GCC \cite{GCC}). Tas nozīmē, ka kross-kompilatoru visticamāk būs jāraksta manuāli, risinot eksistējošās gramatikas konfliktus, un oriģinālvalodas ievērojamu izmaiņu gadījumā būs jāpastrādā abi kompilatori, kas nozīmē divreiz vairāk darba. 

Šīs darbs apskata pieeju, kas lietos eksistējošo valodas parsētāju ka pamatu savam darbam un piedāvās likumu kopu, kas ļaus  modificēt valodas gramatiku parsēšanas laikā. Taču patvaļīgas gramatikas izmaiņas var novest pie nekontrolējamas valodas evolūcijas. Tāpēc aprakstāmā pieejā tiek piedāvātas ierobežotas izmaņu iespējas, kas tiks kontrolētas ar speciāli izveidotas tipu sistēmas palīdzību.

Sistēma ļaus ieviest jaunas konstrukcijas, konstruējot tās no jau eksistējošām valodas vienībām. Tā transformēs programmas gabalus attiecīgi pierakstītiem likumiem tā, lai valodas sākotnējā gramatika būtu tiem pielietojama. Šīs transformācijas korektumu nodrošinās tipu pārbaudes sistēma.

Ļoti līdzīgu uzdevumu, izņemot tikai transformāciju korektuma pārbaudi, pilda arī vispārējie priekšprocesori. Varbūt ir iespējams izveidot minēto sistēmu lietojot kādu no eksistējošām priekšprocesēšanas sistēmām, pievienojot tai kādas korektuma pārbaudes?

Jebkura priekšprocesora viens no galveniem mērķiem ir vienas elementu virknes aizvietošana ar citu. Virknes vienība var būt atšķirīga atkarībā no priekšprocesora, bet parasti šī vienība ir kādu vienas klases rakstzīmju kopa. Klašu daudzums parasti ir fiksēts (skaitlis, burts, tukšums, u.t.t.). Dažreiz zīmes piederība pie klases ir statiska, ka C priekšprocesorā, dažreiz ir dinamiska, ka, piemēram, \TeX{}, kur par atdalītāju var nodefinēt jebkādu specifisku simbolu. Tad apstrāde ir šo virkņu aizvietošana ar citām izveidotām virknēm.

Svarīgākā problēma šādai teksta apstrādes pieejai ir tas, ka tai neiespējams pārbaudīt korektumu. Apskatīsim sekojošu C makro piemēru:
\begin{verbatim}
#define foo(x, y) x y|
\end{verbatim}

Pirmkārt, šādam makro nav iespējams statiski izsecināt rezultātu, jo kaut arī \verb|foo(5, 6)| tiks pārveidots par \verb|5 6|, gan \verb|foo(, 5)|, gan \verb|foo(5, )| tiks pārveidots par \verb|5|. Otrkārt, tā kā komats ir makro daļa, nav iespējams kā pirmo makro argumentu padot virkni \verb|5, 6|. To var izdarīt tikai ievietojot argumentu iekavās, tad \verb|foo((5, 6), 7)|, kas tiks pārveidots par \verb|(5, 6) 7|.

Gadījumā, ja ir nepieciešams saplacināt sarakstu, ir nepieciešams izveidot 2 makro, piemēram:
\begin{verbatim}
#define first(x, y) x
#define bar(x, y) first x y
\end{verbatim}

Tomēr aprakstītais makro strādā tikai gadījumos, kad argumentiem ir pareizs tips. Piemēram, izteiksme \verb|bar((5, 6), x)| tiks pārveidota par \verb|5, x|. Bet izteiksme \verb|bar(5, 6)| tiks pārveidota par \verb|first 5 6|, kaut arī tai vajadzētu izraisīt kļūdu.

Var redzēt, ka vispārīgā gadījumā nav iespējams statiski izveidot nekādus secinājumus, tā kā makro rezultāts ir atkarīgs no argumentiem, kuriem tas ir pielietots. Bet patiesībā arī nekādus dinamiskus secinājumus nav iespējams izveidot, jo apstrādājot tekstu neeksistē korektuma kritēriji.

Tomēr pat neņemot vērā korektuma pierādījumu neiespējamību, makro sistēmai trūkst iespēju, lai izveidot jaunas valodas konstrukcijas. Piemēram, būtu dabiski reprezentēt skaitļa moduli ar pierakstu \verb/|a|/. C priekšprocesors, savukārt, ļauj veidot tikai prefiksa formas funkciju makro un konstanšu makro. Jā arī kāda makro sistēma ļautu izveidot minēto pierakstu, parādītos problēmas gadījumos, kad vienam un tam pašam simbolam eksistē dažas nozīmes, piemēram, ar pierakstu \verb/| (a | b) |/, kam jābūt pārveidotam uz \verb/abs(a | b)/.

Apskatītie piemēri parāda, ka ne kross-kompilēšana, ne programmas teksta priekšprocesēšana vispārpieņemtā veidā neder vēlamā rezultāta sasniegšanai. Par šīs problēmas risinājumu varētu kļūt transformācijas sistēma, kas apstrādā nevis programmas tekstu, bet gan programmas tokenu un pseido-tokenu\footnote{Pseido-tokens ir citu tokenu grupa, kas tiek aizvietota ar vienu objektu. Tas var tikt darīts, lai vienreiz noparsētu izteiksmi nevajadzētu apstrādāt vēlreiz. Tokenu aizvietošana ar pseido-tokeniem notiek gramatikas likumu reducēšanas brīdī. Kad, piemēram, tokenu virkne \texttt{{id:a} '+' {id:b}} tiek atpazīta ka derīga izteiksme gramatikas ietvaros, tā var tikt aizvietota ar pseido-tokenu \texttt{{expr:a + b}}.} virknes. Lai padarītu transformācijas sistēmu vairāk spēcīgu un ļautu atpazīt vispārīgākas virknes, tās makro šabloni tiks paplašināti ar regulāro izteiksmju elementiem, joprojām saglabājot iespēju kontrolēt transformāciju korektumu.

Šādā sistēma dos iespēju paplašināt valodu lietotāja līmenī, nevis kompilatora līmenī. Tas arī dos lielāku brīvību izmaiņu izstrādē, jo lietotājiem būs iespēja veidot makro bibliotēkas ar jaunām iespējām un izplatīt tās. Tā varēs būt pielāgota dažādām valodām, jo tā strādās ārpus paplašināmās valodas gramatikas.

Šī sistēma tiek izstrādāta zinātniskās grupas sastāvā, kurā piedalās cilvēki no Compiler Technology \& Computer Architecture Group, University of Hertfordshire (Hertfordshire, England), Heriot-Watt University (Edinburgh, Scotland) un Moscow Institute of Physics and Technology (Dolgoprudny, Russia).. Tās ideja ir radusies valodas Eq \footnote{Atrodams tiešsaistē - https://github.com/zayac/eq} izstrādes darba gaitā un perspektīvā tiks integrēta ar šīs valodas kompilatoru.