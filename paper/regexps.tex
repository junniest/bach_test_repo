\section{\label{sec:regexps}Regexps}
\fixme{This is a weird draft by Petch}

\subsection{Match as a regular expression}
The left part of the match (without the resulting type) is actually a
regular expression, but with tokens to be matched instead of single
characters. That does not change the concept, because just the same as
we can have a getter for the next symbol in the input stream, we have
the get next token function in the parser. We operate not with an input
stream of symbols, but with an input stream of tokens, generated by the
parser.

Currently our regular expression syntax allows using or \verb/|/ and
asterisk \verb|*| notations. Asterisk is more binding than or, so if you
want to have (a or b) zero to n times you will have to write
\verb/(a|b)*/. The supported syntax can easily be extended, but it is
unnecessary for demonstration purposes. Matching classes of tokens is
unneeded, because the classes can be emulated by using or constructions.
The token count is fairly limited (how many token types do we have?),
unlike the character set that can be used in regular expressions, so
symbol classes like (not a) are not essential. 

The given regular expression is parsed to create an executable
automaton. 

\subsection{Regular expression to NFA}
During parsing each element of the regular expression is depicted with
an object of a specific class. There are three classes with a similar
interface, every class is a matcher object for a construction from the
parsed expression. Token matching is a simple class, whereas asterisk
and or classes are containers for other token matching sequences. The
created objects are then linked in a list. These classes form an
undetermined automata, where a token matching object depicts a transfer
between automata states by a specific token, and all other connections
are actually epsilon transfers (e.g. next element for an object or the
path from asterisk object to it's contents).

\subsection{NFA to DFA}
Next step is to create a DFA out of the created NFA to minimize the
effort needed to execute the given automata. Currently the subset
construction algorithm is used for the determinisation process. (Should
I describe the algorithm? It's pretty standard, although I couldn't find
the name of it). Then the determinate automata created is minimized.
(Should I describe the algorithm, again?)

The created DFA is minimal and therefore the most effective for matching
the given expression. The DFA is represented by a list of objects where
each object contains a map of symbols and objects to which the current
symbol transfers the automaton.

Currently we decided to give up on matching result grouping support in
the regular expressions in favour of maintaining a fully determinate
automaton for each regular expression. Consequently, in the matches'
output, all of the tokens are returned in a single unnested list. (An
option to allow grouping - determinate only parts of the automaton that
are enclosed in braces, then combine the created automata by
consequently glueing the accepting and starting states together. This
approach disallows the combining of several matcher automata into a
single one, as the procedure would ruin the grouping.)

\subsection{Several DFA to single DFA}
Although the prototype doesn't support this feature yet, we intend on
creating a single automaton from the several automata we created. 

For the time being, however, the prototype executes the matches as
follows. We have, for example, $m$ matches, and the simplest of the
decisions on how to match (or not) all of them at one pass through the
source text is to depict them as an NFA with m epsilon branches from the
start state, each of which leads to a DFA we already created. This is a
simple solution and the complexity of it is $O(m)$.

\fixme{Add text and stuff}


In due course we will combine the given m automata into 1 bigger
automata. One by one as the matches are being added to the match list,
the previous and the new automata are combined into a single DFA, so
that it's execution complexity is $O(1)$, a single traverse option for a
single input token.

Some tests should be created to understand whether the combination and
determinisation is time-effective in a general case. It might take more
time than actual execution of the improvised NFA.

\subsection{Optimisation}
\fixme{Write}
\begin{enumerate}
    \item Context matches can be stored for later use, although it is
    unlikely that an exact same match will appear later in the code.
    \item Maybe it is reasonable to create a huge automata for the
    global matches and independent ones for each of the contexts. They
    can be thrown away once function is parsed.
    \item For the big automata - store only a single regexp id in the
    accepting states, no id lists and stuff.
    \item Cache automata while matches come in an uninterrupted
    sequence, once the sequence is disrupted, combine the cached
    automata into a single one and match.
\end{enumerate}
