\documentclass[a4paper]{llncs}

\usepackage[T2A]{fontenc}
\usepackage[utf8x]{inputenc}
\usepackage[russian, english]{babel}
\usepackage{color}
\usepackage[colorlinks,bookmarksopen,bookmarksnumbered,citecolor=red,urlcolor=red]{hyperref}
\usepackage{graphicx}
\usepackage{listings}

\definecolor{lbcolor}{rgb}{0.95,0.95,0.95}
\newcommand{\codesize}{\fontsize{8}{8}\selectfont}
\lstset{% general command to set parameter(s)
    language=C,
    basicstyle=\codesize,          % print whole listing small
    %keywordstyle=\color{black}\bfseries,
                                % underlined bold black keywords
    identifierstyle=,           % nothing happens
    stringstyle=\ttfamily,      % typewriter type for strings
    showstringspaces=false%
}


\newcommand{\fixme}[1]{\vskip 5mm\noindent{\bf FIXME}: {\it #1}}

\author{Jūlija Pečerska\inst{1}, Artjoms Šinkarovs\inst{2}, Pavels Zaičenkovs\inst{3}}
\date{\today}
\title{On dynamic extensions of context-dependent parser\\
       --- Extended Abstract ---}
\institute{
  University of Latvia,
  Raiņa bulvāris 19, Rīga,
  Latvija, LV-1586
\and
  Heriot-Watt University,
  Riccarton, Edinburgh,
  EH14 4AS, United Kingdom
\and
  Moscow Institute of Physics and Technology,
  141700, 9, Institutskii per., Dolgoprudny, 
  Moscow Region, Russia
}


\begin{document}
\maketitle

\begin{abstract}
The idea of using a preprocessor before the actual compilation 
is proven to be useful, however, the automatic verification of
such a programs is extremely hard.  The main difficulty comes
from conceptual separation of grammatical rules of the language
and substitution mechanisms underneath a preprocessor.  C/C++
preprocessor is included into the standard of the languages,
however, expressiveness of this tool is very limited in both
computational power, and syntax extension capabilities.  The
modern programming languages nowadays define a syntax which 
cannot be described precisely using context free grammars.
This problem is well known, and as a solution there are parser
generators like ANTLR which generates LL(*) parsers rather than
LALR/LR.  Nevertheless, a lot of real-world parsers are 
implemented by hand.

In this paper we present a way of building a preprocessor which 
allows dynamic changes of the grammar and which works on top of
any recursive descent parser which meets a certain requirements.
The preprocessing step consists of matching a list of tokens 
against a regular expression built on tokens and encoded 
production names of the given grammar and transforming the
result using a functional language.  We demonstrate that using
the proposed approach it becomes possible to i) give a static
guarantees regarding the preprocessing rules; ii) safely express
non-trivial syntactical constructions; and iii) perform a 
restricted partial evaluation.
\end{abstract}

\input{intro.tex}

\input{parser-model.tex}

\input{dynamic-extensions.tex}

\input{regexps.tex}

\section{Application}
\subsection{Preprocessing}
\subsection{Templates}
\subsection{Optimisation potential}

\section{Evaluation}
Here is a bunch of links for the existing macro-preprocessors:

\begin{tabular}{l | p{.8\textwidth}}
ML/I & \url{http://www.ml1.org.uk/htmldoc/ml1sig.html} \\
GEMA & \url{http://gema.sourceforge.net/new/docs.shtml} \\
GPP  & \url{http://files.nothingisreal.com/software/gpp/gpp.html}
В этой штуке советую заглянуть в ADVANCED EXAMPLES с лямбдой\\
TRAC &
\url{http://web.archive.org/web/20050205172849/http://tracfoundation.org/t2001tech.htm}
Это очень разумная идея правда совсем дохлая -- там тоже
функциональный язык внутри живет, но работает на строках кажись
\end{tabular}

Еще бывают: m4, cpp, lisp/scheme macros, tex?...
\input{lisp-macros.tex}
\input{mli-macros.tex}

\section{Future work}

\bibliographystyle{plain}
\bibliography{paper}


\end{document}
